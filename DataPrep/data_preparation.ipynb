{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "TESTDIR = './../Data/Hyundai/'\n",
    "TESTPATH = 'Lock/'\n",
    "TESTSIG = 'keyfob_signal2023Y1022163258.raw'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate I from Q\n",
    "- we only care about the \"real\" portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim our samples to get rid of the noise from start and end of capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Specify the path to your .raw file\\ndata_dir = \\'./../Data/Hyundai/Unlock/\\'\\n\\n# Get a list of all .raw files in the directory\\nraw_files = [file for file in os.listdir(data_dir) if file.endswith(\".raw\")]\\n\\n# Loop through each .raw file in the directory\\nfor raw_file in raw_files:\\n    file_path = os.path.join(data_dir, raw_file)\\n\\n    # Read the raw file as bytes\\n    with open(file_path, \\'rb\\') as file:\\n        raw_data = file.read()\\n\\n    # Convert the raw data to a NumPy array of complex numbers\\n    # Assuming the raw data consists of interleaved I and Q samples (16-bit signed integers)\\n    raw_array = np.frombuffer(raw_data, dtype=np.int16).astype(np.complex64)\\n\\n    # Extract the in-phase (I) and quadrature (Q) components\\n    I = raw_array.real\\n    Q = raw_array.imag\\n\\n    # Create a time axis for the signal (assuming a fixed sample rate)\\n    sample_rate = 2e6  # Replace with your actual sample rate\\n    time = np.arange(0, len(I)) / sample_rate\\n\\n    # Define the trim duration in seconds\\n    trim_start = 0.005  # 5 ms\\n    trim_end = 0.005    # 5 ms\\n\\n    # Calculate the number of samples to trim\\n    trim_samples = int(sample_rate * (trim_start + trim_end))\\n\\n    # Trim the signal\\n    I_trimmed = I[trim_samples:-trim_samples]\\n    Q_trimmed = Q[trim_samples:-trim_samples]\\n    time_trimmed = time[trim_samples:-trim_samples]\\n\\n    # Plot the I and Q components\\n    plt.figure(figsize=(12, 6))\\n    plt.suptitle(f\\'File: {raw_file}\\')\\n    plt.subplot(2, 1, 1)\\n    plt.plot(time_trimmed, I_trimmed)\\n    plt.title(\\'In-phase Component (Trimmed)\\')\\n    plt.xlabel(\\'Time (s)\\')\\n    plt.grid()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Specify the path to your .raw file\n",
    "data_dir = './../Data/Hyundai/Unlock/'\n",
    "\n",
    "# Get a list of all .raw files in the directory\n",
    "raw_files = [file for file in os.listdir(data_dir) if file.endswith(\".raw\")]\n",
    "\n",
    "# Loop through each .raw file in the directory\n",
    "for raw_file in raw_files:\n",
    "    file_path = os.path.join(data_dir, raw_file)\n",
    "\n",
    "    # Read the raw file as bytes\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "\n",
    "    # Convert the raw data to a NumPy array of complex numbers\n",
    "    # Assuming the raw data consists of interleaved I and Q samples (16-bit signed integers)\n",
    "    raw_array = np.frombuffer(raw_data, dtype=np.int16).astype(np.complex64)\n",
    "\n",
    "    # Extract the in-phase (I) and quadrature (Q) components\n",
    "    I = raw_array.real\n",
    "    Q = raw_array.imag\n",
    "\n",
    "    # Create a time axis for the signal (assuming a fixed sample rate)\n",
    "    sample_rate = 2e6  # Replace with your actual sample rate\n",
    "    time = np.arange(0, len(I)) / sample_rate\n",
    "\n",
    "    # Define the trim duration in seconds\n",
    "    trim_start = 0.005  # 5 ms\n",
    "    trim_end = 0.005    # 5 ms\n",
    "\n",
    "    # Calculate the number of samples to trim\n",
    "    trim_samples = int(sample_rate * (trim_start + trim_end))\n",
    "\n",
    "    # Trim the signal\n",
    "    I_trimmed = I[trim_samples:-trim_samples]\n",
    "    Q_trimmed = Q[trim_samples:-trim_samples]\n",
    "    time_trimmed = time[trim_samples:-trim_samples]\n",
    "\n",
    "    # Plot the I and Q components\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.suptitle(f'File: {raw_file}')\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(time_trimmed, I_trimmed)\n",
    "    plt.title('In-phase Component (Trimmed)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.grid()\"\"\"\n",
    "\n",
    "    #plt.subplot(2, 1, 2)\n",
    "    #plt.plot(time_trimmed, Q_trimmed)\n",
    "    #plt.title('Quadrature Component (Trimmed)')\n",
    "    #plt.xlabel('Time (s)')\n",
    "    #plt.grid()\"\"\"\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Min-Max scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data (I)\n",
    "#I_scaled = scaler.fit_transform(I_trimmed.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_signal_dataframe(data_dir):\n",
    "    I_data_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    for category in os.listdir(data_dir):\n",
    "        category_dir = os.path.join(data_dir, category)\n",
    "        if os.path.isdir(category_dir):\n",
    "            for file in os.listdir(category_dir):\n",
    "                if file.endswith(\".raw\"):\n",
    "                    file_path = os.path.join(category_dir, file)\n",
    "\n",
    "                    with open(file_path, 'rb') as file:\n",
    "                        raw_data = file.read()\n",
    "\n",
    "                    raw_array = np.frombuffer(raw_data, dtype=np.int16).astype(np.complex64)\n",
    "                    I_data = raw_array.real\n",
    "                    Q_data = raw_array.imag\n",
    "\n",
    "                    # Create a time axis for the signal (assuming a fixed sample rate)\n",
    "                    sample_rate = 2e6  # Replace with your actual sample rate\n",
    "                    time = np.arange(0, len(I_data)) / sample_rate\n",
    "\n",
    "                    # Define the trim duration in seconds\n",
    "                    trim_start = 0.005  # 5 ms\n",
    "                    trim_end = 0.005    # 5 ms\n",
    "\n",
    "                    # Calculate the number of samples to trim\n",
    "                    trim_samples = int(sample_rate * (trim_start + trim_end))\n",
    "\n",
    "                    # Trim the signal\n",
    "                    I_trimmed = I_data[trim_samples:-trim_samples]\n",
    "                    time_trimmed = time[trim_samples:-trim_samples]\n",
    "                    #\n",
    "\n",
    "                    # Pad the signal to the desired length\n",
    "                    if len(I_trimmed) < 22766528:\n",
    "                        pad_width = 22766528 - len(I_trimmed)\n",
    "                        I_padded = np.pad(I_trimmed, (0, pad_width), 'constant')\n",
    "                    else:\n",
    "                        I_padded = I_trimmed\n",
    "\n",
    "                    I_scaled = scaler.fit_transform(I_padded.reshape(-1,1))\n",
    "\n",
    "                    I_data_list.append(I_scaled)\n",
    "                    #I_data_list.append(I_trimmed)\n",
    "                    # Process and pack the signals\n",
    "                    labels_list.append(category)\n",
    "    \n",
    "    #processed_signals = process_signals(I_data_list)\n",
    "\n",
    "    one_hot_labels = pd.get_dummies(labels_list, columns=['Label'])                \n",
    "\n",
    "    df = pd.DataFrame({'Signal': I_data_list})\n",
    "    #df = pd.DataFrame({'Signal': processed_signals})\n",
    "    df = pd.concat([df, one_hot_labels], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "data_directory = TESTDIR  # Change this to the path of your 'Data' directory\n",
    "hyundai_df = create_signal_dataframe(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyundai_df.head()\n",
    "#hyundai_df.to_csv('hyundai_data_early.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Signal</th>\n",
       "      <th>Lock</th>\n",
       "      <th>Unlock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.5001626], [0.5001626], [0.5001626], [0.416...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[0.4663887], [0.5330901], [0.5330901], [0.533...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[0.5328125], [0.5328125], [0.5328125], [0.532...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[0.6662338], [0.6662338], [0.5], [0.6662338],...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[0.50009775], [0.4500489], [0.50009775], [0.5...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Signal   Lock  Unlock\n",
       "0  [[0.5001626], [0.5001626], [0.5001626], [0.416...  False    True\n",
       "1  [[0.4663887], [0.5330901], [0.5330901], [0.533...  False    True\n",
       "2  [[0.5328125], [0.5328125], [0.5328125], [0.532...   True   False\n",
       "3  [[0.6662338], [0.6662338], [0.5], [0.6662338],...   True   False\n",
       "4  [[0.50009775], [0.4500489], [0.50009775], [0.5...   True   False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyundai_df_shuffled = hyundai_df.sample(frac=1, random_state=43).reset_index(drop=True)\n",
    "hyundai_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hyundai_df_shuffled['Signal'].values\n",
    "y = hyundai_df_shuffled.drop('Signal',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=43,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = max(X_train,key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22766528"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[4].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22766528"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "#torch.save(model.state_dict(), 'rf_signal_classifier.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
