{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-31 21:47:22.870304: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-31 21:47:22.916236: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-31 21:47:22.916279: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-31 21:47:22.916325: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-31 21:47:22.924525: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-31 21:47:22.925163: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-31 21:47:23.869391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import skimage.io\n",
    "import datetime\n",
    "import random\n",
    "from scipy.signal import spectrogram\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "TESTDIR = './../Data/Hyundai/'\n",
    "TESTPATH = 'Lock/'\n",
    "TESTSIG = 'keyfob_signal2023Y1022163258.raw'\n",
    "\n",
    "TESTOUT = './../Data/MelSpec/Hyundai/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE=640\n",
    "IMG_L = 640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate I from Q\n",
    "- we only care about the \"real\" portion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim our samples to get rid of the noise from start and end of capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Specify the path to your .raw file\\ndata_dir = \\'./../Data/Hyundai/Unlock/\\'\\n\\n# Get a list of all .raw files in the directory\\nraw_files = [file for file in os.listdir(data_dir) if file.endswith(\".raw\")]\\n\\n# Loop through each .raw file in the directory\\nfor raw_file in raw_files:\\n    file_path = os.path.join(data_dir, raw_file)\\n\\n    # Read the raw file as bytes\\n    with open(file_path, \\'rb\\') as file:\\n        raw_data = file.read()\\n\\n    # Convert the raw data to a NumPy array of complex numbers\\n    # Assuming the raw data consists of interleaved I and Q samples (16-bit signed integers)\\n    raw_array = np.frombuffer(raw_data, dtype=np.int16).astype(np.complex64)\\n\\n    # Extract the in-phase (I) and quadrature (Q) components\\n    I = raw_array.real\\n    Q = raw_array.imag\\n\\n    # Create a time axis for the signal (assuming a fixed sample rate)\\n    sample_rate = 2e6  # Replace with your actual sample rate\\n    time = np.arange(0, len(I)) / sample_rate\\n\\n    # Define the trim duration in seconds\\n    trim_start = 0.005  # 5 ms\\n    trim_end = 0.005    # 5 ms\\n\\n    # Calculate the number of samples to trim\\n    trim_samples = int(sample_rate * (trim_start + trim_end))\\n\\n    # Trim the signal\\n    I_trimmed = I[trim_samples:-trim_samples]\\n    Q_trimmed = Q[trim_samples:-trim_samples]\\n    time_trimmed = time[trim_samples:-trim_samples]\\n\\n    # Plot the I and Q components\\n    plt.figure(figsize=(12, 6))\\n    plt.suptitle(f\\'File: {raw_file}\\')\\n    plt.subplot(2, 1, 1)\\n    plt.plot(time_trimmed, I_trimmed)\\n    plt.title(\\'In-phase Component (Trimmed)\\')\\n    plt.xlabel(\\'Time (s)\\')\\n    plt.grid()'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Specify the path to your .raw file\n",
    "data_dir = './../Data/Hyundai/Unlock/'\n",
    "\n",
    "# Get a list of all .raw files in the directory\n",
    "raw_files = [file for file in os.listdir(data_dir) if file.endswith(\".raw\")]\n",
    "\n",
    "# Loop through each .raw file in the directory\n",
    "for raw_file in raw_files:\n",
    "    file_path = os.path.join(data_dir, raw_file)\n",
    "\n",
    "    # Read the raw file as bytes\n",
    "    with open(file_path, 'rb') as file:\n",
    "        raw_data = file.read()\n",
    "\n",
    "    # Convert the raw data to a NumPy array of complex numbers\n",
    "    # Assuming the raw data consists of interleaved I and Q samples (16-bit signed integers)\n",
    "    raw_array = np.frombuffer(raw_data, dtype=np.int16).astype(np.complex64)\n",
    "\n",
    "    # Extract the in-phase (I) and quadrature (Q) components\n",
    "    I = raw_array.real\n",
    "    Q = raw_array.imag\n",
    "\n",
    "    # Create a time axis for the signal (assuming a fixed sample rate)\n",
    "    sample_rate = 2e6  # Replace with your actual sample rate\n",
    "    time = np.arange(0, len(I)) / sample_rate\n",
    "\n",
    "    # Define the trim duration in seconds\n",
    "    trim_start = 0.005  # 5 ms\n",
    "    trim_end = 0.005    # 5 ms\n",
    "\n",
    "    # Calculate the number of samples to trim\n",
    "    trim_samples = int(sample_rate * (trim_start + trim_end))\n",
    "\n",
    "    # Trim the signal\n",
    "    I_trimmed = I[trim_samples:-trim_samples]\n",
    "    Q_trimmed = Q[trim_samples:-trim_samples]\n",
    "    time_trimmed = time[trim_samples:-trim_samples]\n",
    "\n",
    "    # Plot the I and Q components\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.suptitle(f'File: {raw_file}')\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(time_trimmed, I_trimmed)\n",
    "    plt.title('In-phase Component (Trimmed)')\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.grid()\"\"\"\n",
    "\n",
    "    #plt.subplot(2, 1, 2)\n",
    "    #plt.plot(time_trimmed, Q_trimmed)\n",
    "    #plt.title('Quadrature Component (Trimmed)')\n",
    "    #plt.xlabel('Time (s)')\n",
    "    #plt.grid()\"\"\"\n",
    "\n",
    "    #plt.tight_layout()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Min-Max scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the data (I)\n",
    "#I_scaled = scaler.fit_transform(I_trimmed.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 2e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOR IMAGE CNN VERSION ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Lock/keyfob_signal2023Y1022163258_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Lock/keyfob_signal2023Y1022163310_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Lock/keyfob_signal2023Y1022163322_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Lock/keyfob_signal2023Y1022163335_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Lock/keyfob_signal2023Y1022163347_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Lock/keyfob_signal20231022163515_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Lock/keyfob_signal20231022163527_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Lock/keyfob_signal20231022163539_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Lock/keyfob_signal20231022163622_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Lock/keyfob_signal20231022163634_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Lock/keyfob_signal20231022163703_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Lock/keyfob_signal20231022163820_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Unlock/keyfob_signal20231022164121_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Unlock/keyfob_signal20231022164127_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Unlock/keyfob_signal20231022164133_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Unlock/keyfob_signal20231022164139_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Unlock/keyfob_signal20231022164145_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Unlock/keyfob_signal20231022164151_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Unlock/keyfob_signal20231022164157_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Unlock/keyfob_signal20231022164203_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Unlock/keyfob_signal20231022164209_stft.png\n",
      "Saved STFT image to ./../Data/MelSpec/Hyundai/Unlock/keyfob_signal20231022164215_stft.png\n"
     ]
    }
   ],
   "source": [
    "# Directory path containing your RF signal files\n",
    "directory_path = TESTDIR+TESTPATH\n",
    "\n",
    "center_freq = 433e6\n",
    "\n",
    "# List categories (e.g., Category1, Category2)\n",
    "categories = ['Lock', 'Unlock']\n",
    "\n",
    "for category in categories:\n",
    "    input_category_directory = os.path.join(TESTDIR, category)\n",
    "    output_category_directory = os.path.join(TESTOUT, category)\n",
    "\n",
    "    # Ensure the output category directory exists; create it if it doesn't\n",
    "    os.makedirs(output_category_directory, exist_ok=True)\n",
    "\n",
    "    # List all files in the input category directory\n",
    "    file_list = [f for f in os.listdir(input_category_directory) if f.endswith('.raw')]\n",
    "\n",
    "    # Loop through the RF signal files in the category\n",
    "    for file_name in file_list:\n",
    "        # Construct the full file paths\n",
    "        input_file_path = os.path.join(input_category_directory, file_name)\n",
    "        output_file_path = os.path.join(output_category_directory, file_name.replace('.raw', '_stft.png'))\n",
    "\n",
    "        # Read the RF signal data from the input file and convert it to a NumPy array\n",
    "        with open(input_file_path, 'rb') as file:\n",
    "            raw_data = file.read()\n",
    "            rf_signal = np.frombuffer(raw_data, dtype=np.int32).astype(np.float32)\n",
    "\n",
    "        # Calculate the STFT for the RF signal\n",
    "        frequencies, times, Sxx = spectrogram(rf_signal, fs=sample_rate, nperseg=8192, noverlap=512)\n",
    "\n",
    "        # Plot and save the STFT as a grayscale image in the output directory\n",
    "        plt.figure(figsize=(5, 6))\n",
    "        plt.imshow(10 * np.log10(Sxx), cmap='gray', aspect='auto', origin='lower')\n",
    "        plt.colorbar(label='Power Spectral Density (dB/Hz)')\n",
    "        plt.title(f'STFT of {file_name}')\n",
    "        plt.xlabel('Time (s)')\n",
    "        plt.ylabel('Frequency (Hz)')\n",
    "        #plt.savefig(output_file_path)\n",
    "        #plt.imsave(output_file_path, 10 * np.log10(Sxx), cmap='gray')\n",
    "        plt.close()\n",
    "\n",
    "        print(f'Saved STFT image to {output_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory where Mel spectrogram images are stored\n",
    "data_directory = TESTOUT\n",
    "\n",
    "# List of categories (subdirectories in the data directory)\n",
    "categories = os.listdir(data_directory)\n",
    "\n",
    "# Initialize lists to store image data and corresponding labels\n",
    "X = []  # Image data\n",
    "y = []  # Labels\n",
    "\n",
    "# Loop through categories and load images\n",
    "for category in categories:\n",
    "    category_directory = os.path.join(data_directory, category)\n",
    "    files = os.listdir(category_directory)\n",
    "    for file in files:\n",
    "        # Load each image and convert it to a NumPy array\n",
    "        img = tf.keras.preprocessing.image.load_img(os.path.join(category_directory, file), target_size=(IMG_SIZE, IMG_L))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        X.append(img_array)\n",
    "        y.append(category)  # Use category as the label\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "label_to_id = {class_name: class_id for class_id, class_name in enumerate(categories)}\n",
    "y_train = [label_to_id[label] for label in y_train]\n",
    "y_test = [label_to_id[label] for label in y_test]\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(categories)\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Print the shape of the data arrays\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_val shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHANGE THIS TO STAY IN BINARY FOR RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_signal_dataframe(data_dir):\n",
    "    I_data_list = []\n",
    "    labels_list = []\n",
    "    mel_spec_list = []\n",
    "\n",
    "\n",
    "    for category in os.listdir(data_dir):\n",
    "        category_dir = os.path.join(data_dir, category)\n",
    "        if os.path.isdir(category_dir):\n",
    "            for file in os.listdir(category_dir):\n",
    "                if file.endswith(\".raw\"):\n",
    "                    file_path = os.path.join(category_dir, file)\n",
    "\n",
    "                    with open(file_path, 'rb') as file:\n",
    "                        raw_data = file.read()\n",
    "\n",
    "                    # TODO: DO NOT DO THIS for the regression training version strickly for CNN one    \n",
    "                    raw_array = np.frombuffer(raw_data, dtype=np.int16).astype(np.complex64)\n",
    "                    I_data = raw_array.real\n",
    "                    Q_data = raw_array.imag\n",
    "\n",
    "                    # Create a time axis for the signal (assuming a fixed sample rate)\n",
    "                    sample_rate = 2e6  # Replace with your actual sample rate\n",
    "                    time = np.arange(0, len(I_data)) / sample_rate\n",
    "\n",
    "                    # Define the trim duration in seconds\n",
    "                    trim_start = 0.005  # 5 ms\n",
    "                    trim_end = 0.005    # 5 ms\n",
    "\n",
    "                    # Calculate the number of samples to trim\n",
    "                    trim_samples = int(sample_rate * (trim_start + trim_end))\n",
    "\n",
    "                    # Trim the signal\n",
    "                    I_trimmed = I_data[trim_samples:-trim_samples]\n",
    "                    time_trimmed = time[trim_samples:-trim_samples]\n",
    "                    #\n",
    "\n",
    "                    # Pad the signal to the desired length\n",
    "                    if len(I_trimmed) < 22766528:\n",
    "                        pad_width = 22766528 - len(I_trimmed)\n",
    "                        I_padded = np.pad(I_trimmed, (0, pad_width), 'constant')\n",
    "                    else:\n",
    "                        I_padded = I_trimmed\n",
    "\n",
    "\n",
    "                    I_scaled = scaler.fit_transform(I_padded.reshape(-1,1))\n",
    "\n",
    "                    I_data_list.append(I_scaled)\n",
    "                    #I_data_list.append(I_trimmed)\n",
    "                    # Process and pack the signals\n",
    "\n",
    "                    \n",
    "                    labels_list.append(category)\n",
    "    \n",
    "    #processed_signals = process_signals(I_data_list)\n",
    "\n",
    "    one_hot_labels = pd.get_dummies(labels_list, columns=['Label'])                \n",
    "\n",
    "    df = pd.DataFrame({'Signal': I_data_list})\n",
    "    #df = pd.DataFrame({'Signal': processed_signals})\n",
    "    df = pd.concat([df, one_hot_labels], axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "data_directory = TESTDIR  # Change this to the path of your 'Data' directory\n",
    "#hyundai_df, melspec = create_signal_dataframe(data_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyundai_df.head()\n",
    "#hyundai_df.to_csv('hyundai_data_early.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyundai_df_shuffled = hyundai_df.sample(frac=1, random_state=43).reset_index(drop=True)\n",
    "#hyundai_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = hyundai_df_shuffled['Signal'].tolist()\n",
    "#y = hyundai_df_shuffled.drop('Signal',axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=43,\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = max(X_train,key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[4].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "#torch.save(model.state_dict(), 'rf_signal_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten,Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the regression neural network\n",
    "model = tf.keras.Sequential()\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\",input_shape=(IMG_SIZE,IMG_L,3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentrophy', metrics=['accuracy'])  # Mean Squared Error (MSE) loss for regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    epochs=100, \n",
    "    batch_size=3, \n",
    "    validation_data=(X_test, y_test),\n",
    "    verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
